theme: default # default || classic || dark
organization: Cognitive Aerial Robotics Team @ Sun Yat-sen University
twitter: ""
title: Vision-Driven End-to-End Motion Planning for UAVs Using Privileged Imitation Learning
journal: ""
resources:
  paper: # https://openreview.net/
  arxiv: #https://arxiv.org
  code: #https://github.com/denkiwakame/academic-project-template
  video: https://drive.google.com/drive/folders/1fQlAQK69jLvriGrCDQkWBCu6a7jgSyoi?usp=sharing #https://www.youtube.com/embed/onbnb_D1wC8?si=xJczUv716Lt5aO4l&amp;start=1150
  demo: #https://colab.research.google.com/
  huggingface: #https://huggingface.co/
description: academic project page template that supports markdown and KaTeX

image: #https://denkiwakame.github.io/academic-project-template/teaser.jpg
url: #https://denkiwakame.github.io/academic-project-template
speakerdeck: # speakerdeck slide ID
authors:
  - name: Qingrui Zhang
    affiliation: [1]
    url: https://qr-zhang.github.io/
    position: Associate Professor
  - name: Feng Xue
    affiliation: [1]
    position: Master student
    url: #https://thispersondoesnotexist.com/
  - name: Xiang Zhou
    affiliation: [1]
    position: PhD student
    url: #https://thispersondoesnotexist.com/
  - name: Chenghao Yu
    affiliation: [1]
    position: Master student
    url: #https://thispersondoesnotexist.com/
affiliations:
  - School of Aeronautics and Astronautics, Sun Yat-sen University
  # - University of Toronto
meta:
  # - '*work done while she was interning at Pixel Genius Lab.'
bibtex: >
  # @article{doe2024superai,
  #   author    = {Jane Doe and John Smith},
  #   title     = {Unleashing the Power of Super AI: Transforming the Future of Technology},
  #   journal   = {Journal of Superintelligent Systems},
  #   year      = {2024},
  #   volume    = {99},
  #   number    = {1},
  #   pages     = {1-42},
  #   month     = {January},
  #   keywords  = {Super AI, Machine Learning, Artificial Intelligence, Technological Innovation},
  #   doi       = {10.9999/jsis.2024.001},
  #   url       = {https://www.example.com/superai-article},
  #   note      = {This paper sets the benchmark for future AI research and applications.}
  # }

teaser: exp_at_pillar_environment.jpg #teaser.jpg
abstract: |
 Autonomous navigation in unknown cluttered environments remains a challenge for vision-based unmanned aerial vehicles (UAVs), 
 particularly under limited onboard resources. In this paper, we present PILOT, a privileged imitation learning algorithm for 
 vision-based end-to-end UAV motion planning in cluttered, unstructured, and congested environments. A model predictive control 
 (MPC) expert with access to privileged information is introduced to generate collision-free demonstration trajectories that 
 guide the learning process of PILOT. A temporal convolutional network (TCN) is used to implicitly reconstruct all unobservable 
 privileged information by fusing sequential visual observations and historical velocity measurements. The TCN module enables a 
 UAV to achieve extended spatial awareness beyond immediate visual perception, thereby enhancing the generalization capability 
 of the learned planner. A trajectory parameterization technique is further introduced to improve motion smoothness and ensure 
 satisfaction of UAV dynamic constraints. The proposed PILOT framework is thoroughly evaluated through extensive numerical simulations 
 and diverse real-world experiments. The evaluation results demonstrate that the planner learned by PILOT achieves consistent performance 
 comparable to the MPC expert with a significant reduction computation time by more than 80% across diverse environments and different 
 UAV platforms. Ablation studies have illustrated the efficiency of both the TCN and the trajectory parameterization modules. 
 Real-world tests on a custom-built quadrotor have corroborated that the learned motion planner can generate feasible, collision-free 
 trajectories in real time directly using noisy visual observations. Both simulations and experimental results have confirmed PILOTâ€™s 
 capability of strong generalization to previously unseen environments.
body:
  - title: Simulation and Experiments # Media template
    text: |
