theme: default # default || classic || dark
organization: "Cognitive Aerial Robotics Team @ Sun Yat-sen University"
twitter: ""
title: Vision-Driven End-to-End Motion Planning for UAVs Using Privileged Imitation Learning
journal: ""
resources:
  paper: "https://qr-zhang.github.io/PILOT/"  # https://openreview.net/
  arxiv: "https://qr-zhang.github.io/PILOT/" # https://arxiv.org
  code:  "https://qr-zhang.github.io/PILOT/" # https://github.com/denkiwakame/academic-project-template
  video: "https://drive.google.com/file/d/1OxaRQNORNBdd60U-jwd0jLW29GQ-hgIE/preview" # "https://drive.google.com/drive/folders/1fQlAQK69jLvriGrCDQkWBCu6a7jgSyoi?usp=sharing"
  huggingface: # https://huggingface.co/
description:  "This an academic page for our PILOT project"  # academic project page template that supports markdown and KaTeX

image: ""  # https://denkiwakame.github.io/academic-project-template/teaser.jpg
url:  "" # https://denkiwakame.github.io/academic-project-template
speakerdeck:  "" # speakerdeck slide ID
authors:
  - name: Qingrui Zhang
    affiliation: [1]
    url: "https://qr-zhang.github.io/"
    position: Associate Professor
  - name: Feng Xue
    affiliation: [1]
    position: Master student
    url:  "" #https://thispersondoesnotexist.com/
  - name: Xiang Zhou
    affiliation: [1]
    position: PhD student
    url:  ""  #https://thispersondoesnotexist.com/
  - name: Chenghao Yu
    affiliation: [1]
    position: Master student
    url:  "" #https://thispersondoesnotexist.com/
affiliations:
  - School of Aeronautics and Astronautics, Sun Yat-sen University
# meta:
#   - '*Equal Contribution'
# bibtex: #>
#   # @article{doe2024superai,
#   #   author    = {Jane Doe and John Smith},
#   #   title     = {Unleashing the Power of Super AI: Transforming the Future of Technology},
#   #   journal   = {Journal of Superintelligent Systems},
#   #   year      = {2024},
#   #   volume    = {99},
#   #   number    = {1},
#   #   pages     = {1-42},
#   #   month     = {January},
#   #   keywords  = {Super AI, Machine Learning, Artificial Intelligence, Technological Innovation},
#   #   doi       = {10.9999/jsis.2024.001},
#   #   url       = {https://www.example.com/superai-article},
#   #   note      = {This paper sets the benchmark for future AI research and applications.}
#   # }

teaser: exp_at_pillar_environment.jpg #teaser.jpg
abstract: |
 Autonomous navigation in unknown cluttered environments remains a challenge for vision-based unmanned aerial vehicles (UAVs), 
 particularly under limited onboard resources. In this paper, we present PILOT, a privileged imitation learning algorithm for 
 vision-based end-to-end UAV motion planning in cluttered, unstructured, and congested environments. A model predictive control 
 (MPC) expert with access to privileged information is introduced to generate collision-free demonstration trajectories that 
 guide the learning process of PILOT. A temporal convolutional network (TCN) is used to implicitly reconstruct all unobservable 
 privileged information by fusing sequential visual observations and historical velocity measurements. The TCN module enables a 
 UAV to achieve extended spatial awareness beyond immediate visual perception, thereby enhancing the generalization capability 
 of the learned planner. A trajectory parameterization technique is further introduced to improve motion smoothness and ensure 
 satisfaction of UAV dynamic constraints. The proposed PILOT framework is thoroughly evaluated through extensive numerical simulations 
 and diverse real-world experiments. The evaluation results demonstrate that the planner learned by PILOT achieves consistent performance 
 comparable to the MPC expert with a significant reduction computation time by more than 80% across diverse environments and different 
 UAV platforms. Ablation studies have illustrated the efficiency of both the TCN and the trajectory parameterization modules. 
 Real-world tests on a custom-built quadrotor have corroborated that the learned motion planner can generate feasible, collision-free 
 trajectories in real time directly using noisy visual observations. Both simulations and experimental results have confirmed PILOTâ€™s 
 capability of strong generalization to previously unseen environments.


body:
  - title: Simulation and Experiment
    text: |
      ### Mediafile Path
      Files in `public/` can be referenced directly: `<img src="001.jpg" />`

      ### UIKit Components
      This template supports all UIKit components.
      To check available components, refer to the [UIKit documentation](https://getuikit.com/docs).
      [Slideshow](https://getuikit.com/docs/slideshow) example

      </div>
      <div uk-slideshow="animation: push">
        <div class="uk-position-relative uk-visible-toggle uk-light" tabindex="-1">
          <div class="uk-slideshow-items">
            <div>
              <img src="001.jpg" alt="" uk-cover>
            </div>
            <div>
              <img src="002.jpg" alt="" uk-cover>
            </div>
            <div>
              <img src="003.jpg" alt="" uk-cover>
            </div>
          </div>
          <a class="uk-position-center-left uk-position-small uk-hidden-hover" href uk-slidenav-previous uk-slideshow-item="previous"></a>
          <a class="uk-position-center-right uk-position-small uk-hidden-hover" href uk-slidenav-next uk-slideshow-item="next"></a>
        </div>
        <ul class="uk-slideshow-nav uk-dotnav uk-flex-center uk-margin"></ul>
      </div>

      [Grid system](https://getuikit.com/docs/grid) example
      <div class="uk-grid-small uk-child-width-1-2 uk-child-width-1-3@m" uk-grid>
        <div>
          <img src="001.jpg">
          <span class="uk-text-meta">Fig1 - caption example</figcaption>
        </div>
        <div>
          <img src="002.jpg" />
          <span class="uk-text-meta">Fig2 - caption example</figcaption>
        </div>
        <div>
          <img src="003.jpg">
          <span class="uk-text-meta">Fig3 - caption example</figcaption>
        </div>
      </div>
      
      Simulation Results
      [Video](https://getuikit.com/docs/video) and [Slider](https://getuikit.com/docs/slider) component example
      <div uk-slider>
        <div class="uk-slider-items uk-grid-small uk-child-width-1-1 uk-child-width-1-2@m uk-grid">
        <div class="publication-video">
        <iframe src="https://drive.google.com/file/d/1N-mTbLiDIFgVX5JmJtPSM07e0DMLVQqg/preview" width="480" height="360" allow="autoplay"></iframe>
         </div>
        <div class="publication-video">
        <iframe src="https://drive.google.com/file/d/1OxaRQNORNBdd60U-jwd0jLW29GQ-hgIE/preview" width="480" height="360" allow="autoplay"></iframe>
         </div>
        </div>
        <div class="uk-flex uk-flex-center uk-margin-small">
          <a class="uk-icon-button" href uk-slidenav-previous uk-slider-item="previous"></a>
          <a class="uk-icon-button uk-margin-small-left" href uk-slidenav-next uk-slider-item="next"></a>
        </div>
      </div>


  # - title: License
  #   text: |
  #     This template is provided under the [Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)](https://creativecommons.org/licenses/by-sa/4.0/) license.
  #     You are free to use and modify the code in your project as long as you include a link to this [GitHub repository](https://github.com/denkiwakame/academic-project-template) in your footer.

projects: # relevant projects
  - title: "" # Relevant Project I
    description: ""  # abstract text
    img:  ""  # https://getuikit.com/docs/images/light.jpg
    journal:  ""  # "ABCD'23"
    url:  ""  # https://denkiwakame.github.io/academic-project-template/
  - title:  ""  # Relevant Project II
    description:  ""  # abstract text
    img:  ""  # 001.jpg
    journal:  ""  # "EFGH'22"
    url:  ""  # https://denkiwakame.github.io/academic-project-template/
